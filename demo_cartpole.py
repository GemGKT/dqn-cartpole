import gym
import torch
import numpy as np
from model import DQN
import os
import imageio

# T·∫°o th∆∞ m·ª•c videos n·∫øu ch∆∞a c√≥
os.makedirs(r"E:\Codes\Reinforcement_Learning\Week_1\cartpole_dqn\videos", exist_ok=True)

# Kh·ªüi t·∫°o m√¥i tr∆∞·ªùng ghi frame
env = gym.make("CartPole-v1", render_mode="rgb_array")
input_dim = env.observation_space.shape[0]
output_dim = env.action_space.n

# Load m√¥ h√¨nh ƒë√£ h·ªçc
model = DQN(input_dim, output_dim)
model.load_state_dict(torch.load(r"E:\Codes\Reinforcement_Learning\Week_1\cartpole_dqn\best_dqn_cartpole.pt"))
model.eval()

# Reset m√¥i tr∆∞·ªùng
state, _ = env.reset()
done = False
total_reward = 0
frames = []

while not done:
    # L·∫•y frame hi·ªán t·∫°i ƒë·ªÉ ghi video
    frame = env.render()
    frames.append(frame)

    # Ch·ªçn h√†nh ƒë·ªông theo policy
    with torch.no_grad():
        state_tensor = torch.FloatTensor(state).unsqueeze(0)
        q_values = model(state_tensor)
        action = q_values.argmax().item()

    next_state, reward, terminated, truncated, _ = env.step(action)
    done = terminated or truncated
    state = next_state
    total_reward += reward

env.close()

# Ghi video
video_path = r"E:\Codes\Reinforcement_Learning\Week_1\cartpole_dqn\videos\demo_ep1.mp4"
imageio.mimsave(video_path, frames, fps=30)

# Th√¥ng tin k·∫øt qu·∫£
print("=" * 40)
print("üéÆ DQN CartPole Demo")
print(f"üèÜ Total Reward: {total_reward}")
print(f"üé• Video saved to: {video_path}")
print("=" * 40)
